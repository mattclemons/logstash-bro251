########################
# logstash Configuration Files - Bro IDS Logs
# Created by 505Forensics (http://www.505forensics.com)
# MIT License, so do what you want with it!
#
# For use with logstash, elasticsearch, and kibana to analyze logs
#
# Usage: Reference this config file for your instance of logstash to parse Bro files logs
#
# Limitations: Standard bro log delimiter is tab.
#
#######################

input {
  file {
    type => "files_log"
    start_position => "end"
    sincedb_path => "/var/tmp/.bro_files_sincedb"

    #Edit the following path to reflect the location of your log files. You can also change the extension if you use something else
    path => "/data/bro/logs/current/files.log"
  }
}

filter {

  #Let's get rid of those header lines; they begin with a hash
  if [message] =~ /^#/ {
    drop { }
  }

  #Now, using the csv filter, we can define the Bro files log fields.  #files.log:#fields  ts    fuid    tx_hosts        rx_hosts        conn_uids       source  depth   analyzers       mime_type       filename        duration        local_orig      is_orig seen_bytes      total_bytes     missing_bytes   overflow_bytes  timedout        parent_fuid     md5     sha1    sha256  extracted       extracted_cutoff        extracted_size

  if [type] == "files_log" {
    csv {

      columns => ["ts","fuid","tx_hosts","rx_hosts","conn_uids","source","depth","analyzers","mime_type","filename","duration","local_orig","is_orig","seen_bytes","total_bytes","missing_bytes","overflow_bytes","timedout",
"parent_fuid","md5","sha1","sha256","extracted","extracted_cutoff","extracted_size"]

      #If you use a custom delimiter, change the following value in between the quotes to your delimiter. Otherwise, leave the next line alone.
      separator => "	"
    }

    #Let's convert our timestamp into the 'ts' field, so we can use Kibana features natively
    date {
      match => [ "ts", "UNIX" ]
    }

    # add geoip attributes
    geoip {
      source => "tx_hosts"
      target => "tx_hosts_geoip"
    }
    geoip {
      source => "rx_hosts"
      target => "rx_hosts_geoip"
    }

    mutate {
      convert => [ "duration", "float" ]
      convert => [ "depth", "integer" ]
      convert => [ "seen_bytes", "integer" ]
      convert => [ "total_bytes", "integer" ]
      convert => [ "missing_bytes", "integer" ]
      convert => [ "overflow_bytes", "integer" ]
    }
  }
}

output {
elasticsearch { hosts => ["Elasticsearch.IP:9200"] }
}
